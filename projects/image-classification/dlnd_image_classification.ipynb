{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb1cdc44278>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.abs(x - 128) / 128\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    n = np.zeros(shape=(len(x), 10))\n",
    "    n[np.arange(len(x)), x] = 1\n",
    "    return n\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, (None, ) + image_shape,\n",
    "                          name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None, n_classes],\n",
    "                          name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # set weight and bias\n",
    "    input_shape = x_tensor.shape.as_list()[-1]\n",
    "    weight = tf.Variable(tf.truncated_normal([conv_ksize[0], conv_ksize[1],\n",
    "                                              input_shape, conv_num_outputs],\n",
    "                                             stddev=0.04))\n",
    "    bias = tf.Variable(tf.truncated_normal([conv_num_outputs], stddev=0.05))\n",
    "    \n",
    "    # create conv2d\n",
    "    conv = tf.nn.conv2d(x_tensor, weight,\n",
    "                        strides=[1, conv_strides[0], conv_strides[1], 1],\n",
    "                        padding='SAME')\n",
    "    \n",
    "    # add bias\n",
    "    conv = tf.nn.bias_add(conv, bias)\n",
    "    \n",
    "    # add non-linear activation function\n",
    "    conv = tf.nn.relu(conv)\n",
    "    \n",
    "    # max pooling\n",
    "    conv = tf.nn.max_pool(conv,\n",
    "                          ksize=[1, pool_ksize[0], pool_ksize[1], 1],\n",
    "                          strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "    return conv\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_size = x_tensor.get_shape().as_list()\n",
    "    return tf.reshape(x_tensor, [-1, np.prod(np.array(x_size[1:]))])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    # set weight and bias\n",
    "    input_shape = x_tensor.get_shape().as_list()[1]\n",
    "    weight = tf.Variable(tf.truncated_normal([input_shape, num_outputs],\n",
    "                                             stddev=0.04))\n",
    "    bias = tf.Variable(tf.truncated_normal([num_outputs], stddev=0.05))\n",
    "    \n",
    "    # linear combination\n",
    "    fully_conn_layer = tf.add(tf.matmul(x_tensor, weight), bias)\n",
    "    fully_conn_layer = tf.nn.relu(fully_conn_layer)\n",
    "    \n",
    "    return fully_conn_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input_shape = x_tensor.get_shape().as_list()[1]\n",
    "    w = tf.Variable(tf.truncated_normal([input_shape, num_outputs],\n",
    "                                        stddev=0.04))\n",
    "    b = tf.Variable(tf.truncated_normal([num_outputs], stddev=0.05))\n",
    "    \n",
    "    output_layer = tf.add(tf.matmul(x_tensor, w), b)\n",
    "    return output_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv1 = conv2d_maxpool(x, 32, [2, 2], [1, 1], [2, 2], [2, 2])\n",
    "    conv2 = conv2d_maxpool(conv1, 64, [3, 3], [1, 1], [1, 1], [1, 1])\n",
    "    conv3 = conv2d_maxpool(conv2, 128, [2, 2], [1, 1], [2, 2], [2, 2])\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flatten_conv = flatten(conv3)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fully_1 = fully_conn(flatten_conv, 1024)\n",
    "    fully_1 = tf.nn.dropout(fully_1, keep_prob)\n",
    "    \n",
    "    fully_2 = fully_conn(fully_1, 512)\n",
    "#     fully_2 = tf.nn.dropout(fully_2, keep_prob)\n",
    "    \n",
    "#     fully_3 = fully_conn(fully_2, 256)\n",
    "#     fully_3 = tf.nn.dropout(fully_3, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    logit = output(fully_1, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return logit\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={x: feature_batch,\n",
    "                                      y: label_batch,\n",
    "                                      keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = session.run(cost, feed_dict={x: feature_batch,\n",
    "                                        y: label_batch,\n",
    "                                        keep_prob: 1})\n",
    "    \n",
    "    accu = session.run(accuracy, feed_dict={x: valid_features,\n",
    "                                            y: valid_labels,\n",
    "                                            keep_prob: 1})\n",
    "    \n",
    "    print('Loss: {:>10.6f} Validation Accuracy: {:.6f}'.format(loss, accu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 2048\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:   2.279104 Validation Accuracy: 0.099600\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:   2.164067 Validation Accuracy: 0.221400\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:   2.074322 Validation Accuracy: 0.272000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:   2.033987 Validation Accuracy: 0.287400\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:   1.944575 Validation Accuracy: 0.309200\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:   1.872478 Validation Accuracy: 0.328600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:   1.817329 Validation Accuracy: 0.341000\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:   1.759807 Validation Accuracy: 0.355600\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:   1.706281 Validation Accuracy: 0.361400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:   1.653892 Validation Accuracy: 0.379000\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:   1.606988 Validation Accuracy: 0.384400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:   1.558028 Validation Accuracy: 0.396600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:   1.516842 Validation Accuracy: 0.401600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:   1.458091 Validation Accuracy: 0.415800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:   1.443384 Validation Accuracy: 0.413000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:   1.382183 Validation Accuracy: 0.423400\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:   1.348468 Validation Accuracy: 0.432200\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:   1.301800 Validation Accuracy: 0.441600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:   1.254268 Validation Accuracy: 0.449200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:   1.241751 Validation Accuracy: 0.445400\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:   1.180878 Validation Accuracy: 0.453200\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:   1.127873 Validation Accuracy: 0.461000\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:   1.087011 Validation Accuracy: 0.469400\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:   1.052567 Validation Accuracy: 0.474200\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:   0.995356 Validation Accuracy: 0.484400\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:   0.981123 Validation Accuracy: 0.479400\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:   0.923068 Validation Accuracy: 0.485200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:   0.882325 Validation Accuracy: 0.486400\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:   0.825341 Validation Accuracy: 0.492600\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:   0.968610 Validation Accuracy: 0.462800\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:   0.808213 Validation Accuracy: 0.498600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:   0.742164 Validation Accuracy: 0.494400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:   0.692398 Validation Accuracy: 0.504600\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:   0.654267 Validation Accuracy: 0.508000\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:   0.594553 Validation Accuracy: 0.511800\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:   0.561788 Validation Accuracy: 0.517800\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:   0.533970 Validation Accuracy: 0.516800\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:   0.501627 Validation Accuracy: 0.514600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:   0.473340 Validation Accuracy: 0.520600\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:   0.437791 Validation Accuracy: 0.516000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:   0.403526 Validation Accuracy: 0.519400\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:   0.399593 Validation Accuracy: 0.508400\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:   0.341612 Validation Accuracy: 0.523800\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:   0.313840 Validation Accuracy: 0.522000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:   0.293119 Validation Accuracy: 0.520400\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:   0.280734 Validation Accuracy: 0.517800\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:   0.276383 Validation Accuracy: 0.517400\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:   0.249390 Validation Accuracy: 0.520200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:   0.238945 Validation Accuracy: 0.516800\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:   0.219148 Validation Accuracy: 0.523000\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:   0.205039 Validation Accuracy: 0.518400\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:   0.219696 Validation Accuracy: 0.512400\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:   0.192357 Validation Accuracy: 0.521400\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:   0.160808 Validation Accuracy: 0.521800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:   0.132187 Validation Accuracy: 0.529400\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:   0.109370 Validation Accuracy: 0.530600\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:   0.106737 Validation Accuracy: 0.529200\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:   0.096647 Validation Accuracy: 0.526000\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:   0.111304 Validation Accuracy: 0.514400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:   0.119346 Validation Accuracy: 0.514800\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:   0.135820 Validation Accuracy: 0.505200\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:   0.093126 Validation Accuracy: 0.526400\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:   0.081288 Validation Accuracy: 0.519000\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:   0.060873 Validation Accuracy: 0.534400\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:   0.064346 Validation Accuracy: 0.520200\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:   0.083079 Validation Accuracy: 0.502000\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:   0.182699 Validation Accuracy: 0.468400\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:   0.127945 Validation Accuracy: 0.488200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:   0.131756 Validation Accuracy: 0.500600\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:   0.103828 Validation Accuracy: 0.499600\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:   0.126164 Validation Accuracy: 0.484400\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:   0.086693 Validation Accuracy: 0.498600\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:   0.093835 Validation Accuracy: 0.510000\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:   0.054104 Validation Accuracy: 0.517000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:   0.042535 Validation Accuracy: 0.519800\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:   0.039913 Validation Accuracy: 0.519200\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:   0.052311 Validation Accuracy: 0.498600\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:   0.031371 Validation Accuracy: 0.519800\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:   0.024733 Validation Accuracy: 0.530000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:   0.018234 Validation Accuracy: 0.533600\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:   0.016489 Validation Accuracy: 0.531000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:   0.013103 Validation Accuracy: 0.529200\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:   0.012093 Validation Accuracy: 0.534400\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:   0.011216 Validation Accuracy: 0.533400\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:   0.011175 Validation Accuracy: 0.530400\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:   0.010497 Validation Accuracy: 0.535800\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:   0.009840 Validation Accuracy: 0.537400\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:   0.008048 Validation Accuracy: 0.538800\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:   0.008521 Validation Accuracy: 0.525600\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:   0.008219 Validation Accuracy: 0.524800\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:   0.007851 Validation Accuracy: 0.528400\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:   0.006905 Validation Accuracy: 0.529800\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:   0.005993 Validation Accuracy: 0.534400\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:   0.005931 Validation Accuracy: 0.535000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:   0.005142 Validation Accuracy: 0.536600\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:   0.006142 Validation Accuracy: 0.530400\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:   0.005346 Validation Accuracy: 0.527000\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:   0.004547 Validation Accuracy: 0.531000\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:   0.004512 Validation Accuracy: 0.527600\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:   0.003923 Validation Accuracy: 0.533200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:   2.291238 Validation Accuracy: 0.119200\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:   2.176341 Validation Accuracy: 0.222800\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:   2.104931 Validation Accuracy: 0.247200\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:   1.971447 Validation Accuracy: 0.288800\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:   1.908842 Validation Accuracy: 0.313000\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:   1.882722 Validation Accuracy: 0.331200\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:   1.789191 Validation Accuracy: 0.351800\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:   1.788126 Validation Accuracy: 0.358000\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:   1.726706 Validation Accuracy: 0.378600\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:   1.680727 Validation Accuracy: 0.384000\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:   1.689359 Validation Accuracy: 0.383800\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:   1.615658 Validation Accuracy: 0.407400\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:   1.612258 Validation Accuracy: 0.418600\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:   1.548931 Validation Accuracy: 0.425800\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:   1.513873 Validation Accuracy: 0.443800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:   1.880237 Validation Accuracy: 0.337000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:   1.576963 Validation Accuracy: 0.420000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:   1.557490 Validation Accuracy: 0.420800\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:   1.489785 Validation Accuracy: 0.441200\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:   1.491219 Validation Accuracy: 0.434200\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:   1.463646 Validation Accuracy: 0.459400\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:   1.426670 Validation Accuracy: 0.467800\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:   1.384618 Validation Accuracy: 0.472000\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:   1.345614 Validation Accuracy: 0.477800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:   1.370300 Validation Accuracy: 0.487800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:   1.358391 Validation Accuracy: 0.494200\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:   1.328160 Validation Accuracy: 0.493600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:   1.290410 Validation Accuracy: 0.489400\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:   1.267571 Validation Accuracy: 0.505800\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:   1.289619 Validation Accuracy: 0.513600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:   1.281221 Validation Accuracy: 0.513200\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:   1.247326 Validation Accuracy: 0.517000\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:   1.208254 Validation Accuracy: 0.513600\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:   1.192517 Validation Accuracy: 0.518400\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:   1.230555 Validation Accuracy: 0.526600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:   1.209327 Validation Accuracy: 0.532800\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:   1.195427 Validation Accuracy: 0.522800\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:   1.131886 Validation Accuracy: 0.542400\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:   1.118511 Validation Accuracy: 0.534400\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:   1.129552 Validation Accuracy: 0.548000\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:   1.130395 Validation Accuracy: 0.549800\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:   1.111207 Validation Accuracy: 0.550800\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:   1.064918 Validation Accuracy: 0.544200\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:   1.037675 Validation Accuracy: 0.557000\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:   1.069090 Validation Accuracy: 0.565800\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:   1.067736 Validation Accuracy: 0.562600\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:   1.061703 Validation Accuracy: 0.556600\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:   1.039372 Validation Accuracy: 0.549800\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:   0.984723 Validation Accuracy: 0.562800\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:   1.004848 Validation Accuracy: 0.576400\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:   0.996398 Validation Accuracy: 0.572000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:   0.988486 Validation Accuracy: 0.568400\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:   0.935735 Validation Accuracy: 0.575600\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:   0.921360 Validation Accuracy: 0.568800\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:   0.964659 Validation Accuracy: 0.576000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:   0.955409 Validation Accuracy: 0.573400\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:   0.933395 Validation Accuracy: 0.578600\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:   0.905939 Validation Accuracy: 0.575000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:   0.857011 Validation Accuracy: 0.575400\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:   0.896038 Validation Accuracy: 0.587800\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:   0.886737 Validation Accuracy: 0.581800\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:   0.899649 Validation Accuracy: 0.576400\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:   0.859582 Validation Accuracy: 0.582600\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:   0.802542 Validation Accuracy: 0.585600\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:   0.844906 Validation Accuracy: 0.589800\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:   0.835416 Validation Accuracy: 0.585200\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:   0.829784 Validation Accuracy: 0.589400\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:   0.785314 Validation Accuracy: 0.589800\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:   0.771730 Validation Accuracy: 0.585600\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:   0.786564 Validation Accuracy: 0.591800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:   0.772784 Validation Accuracy: 0.594200\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:   0.777084 Validation Accuracy: 0.591800\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:   0.744723 Validation Accuracy: 0.588800\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:   0.748696 Validation Accuracy: 0.577000\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:   0.791144 Validation Accuracy: 0.576000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:   0.770305 Validation Accuracy: 0.582200\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:   0.754566 Validation Accuracy: 0.590400\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:   0.767208 Validation Accuracy: 0.567200\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:   0.702323 Validation Accuracy: 0.595400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:   0.726753 Validation Accuracy: 0.586000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:   0.701323 Validation Accuracy: 0.594000\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:   0.697098 Validation Accuracy: 0.591600\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:   0.661001 Validation Accuracy: 0.594200\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:   0.655575 Validation Accuracy: 0.595800\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:   0.636199 Validation Accuracy: 0.606800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:   0.617356 Validation Accuracy: 0.607400\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:   0.622808 Validation Accuracy: 0.610000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:   0.580971 Validation Accuracy: 0.606600\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:   0.575783 Validation Accuracy: 0.613400\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:   0.583526 Validation Accuracy: 0.611400\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:   0.569592 Validation Accuracy: 0.611400\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:   0.584454 Validation Accuracy: 0.603000\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:   0.548580 Validation Accuracy: 0.616800\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:   0.535590 Validation Accuracy: 0.611400\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:   0.537836 Validation Accuracy: 0.611200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:   0.507347 Validation Accuracy: 0.620600\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:   0.522617 Validation Accuracy: 0.612600\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:   0.493481 Validation Accuracy: 0.613200\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:   0.481120 Validation Accuracy: 0.613600\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:   0.505231 Validation Accuracy: 0.612200\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:   0.477778 Validation Accuracy: 0.621400\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:   0.484100 Validation Accuracy: 0.609800\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:   0.454385 Validation Accuracy: 0.616200\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:   0.437581 Validation Accuracy: 0.614000\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:   0.440233 Validation Accuracy: 0.611000\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:   0.425608 Validation Accuracy: 0.613800\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:   0.423678 Validation Accuracy: 0.622200\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:   0.376035 Validation Accuracy: 0.625800\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:   0.373502 Validation Accuracy: 0.625400\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:   0.382682 Validation Accuracy: 0.621400\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:   0.384928 Validation Accuracy: 0.622000\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:   0.375142 Validation Accuracy: 0.625600\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:   0.337591 Validation Accuracy: 0.627400\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:   0.344794 Validation Accuracy: 0.628000\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:   0.340049 Validation Accuracy: 0.624200\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:   0.347355 Validation Accuracy: 0.624800\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:   0.336648 Validation Accuracy: 0.626600\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:   0.301057 Validation Accuracy: 0.629600\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:   0.294237 Validation Accuracy: 0.630800\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:   0.298492 Validation Accuracy: 0.624800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:   0.302673 Validation Accuracy: 0.623000\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:   0.318375 Validation Accuracy: 0.617600\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:   0.269291 Validation Accuracy: 0.631000\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:   0.257982 Validation Accuracy: 0.629400\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:   0.272354 Validation Accuracy: 0.622000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:   0.264384 Validation Accuracy: 0.628400\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:   0.310700 Validation Accuracy: 0.610200\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:   0.288420 Validation Accuracy: 0.612800\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:   0.282865 Validation Accuracy: 0.604800\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:   0.273611 Validation Accuracy: 0.620200\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:   0.277752 Validation Accuracy: 0.616600\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:   0.301207 Validation Accuracy: 0.609400\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:   0.283983 Validation Accuracy: 0.594200\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:   0.269238 Validation Accuracy: 0.604000\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:   0.313721 Validation Accuracy: 0.602200\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:   0.231870 Validation Accuracy: 0.621200\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:   0.260802 Validation Accuracy: 0.619800\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:   0.257168 Validation Accuracy: 0.612600\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:   0.212506 Validation Accuracy: 0.627800\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:   0.213428 Validation Accuracy: 0.621200\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:   0.219179 Validation Accuracy: 0.616600\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:   0.255001 Validation Accuracy: 0.604000\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:   0.220217 Validation Accuracy: 0.608600\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:   0.204939 Validation Accuracy: 0.620800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:   0.196584 Validation Accuracy: 0.616800\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:   0.204517 Validation Accuracy: 0.620200\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:   0.206508 Validation Accuracy: 0.623200\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:   0.205344 Validation Accuracy: 0.604600\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:   0.191637 Validation Accuracy: 0.613600\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:   0.219763 Validation Accuracy: 0.614200\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:   0.198786 Validation Accuracy: 0.609800\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:   0.218958 Validation Accuracy: 0.612600\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:   0.175899 Validation Accuracy: 0.626000\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:   0.165398 Validation Accuracy: 0.618400\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:   0.168412 Validation Accuracy: 0.629600\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:   0.160931 Validation Accuracy: 0.621600\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:   0.158119 Validation Accuracy: 0.626200\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:   0.143032 Validation Accuracy: 0.631000\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:   0.115701 Validation Accuracy: 0.629800\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:   0.132734 Validation Accuracy: 0.633600\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:   0.123336 Validation Accuracy: 0.628400\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:   0.153059 Validation Accuracy: 0.616600\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:   0.134111 Validation Accuracy: 0.617600\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:   0.106657 Validation Accuracy: 0.631400\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:   0.115247 Validation Accuracy: 0.625200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:   0.100670 Validation Accuracy: 0.630800\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:   0.103137 Validation Accuracy: 0.632600\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:   0.088383 Validation Accuracy: 0.635200\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:   0.076895 Validation Accuracy: 0.641200\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:   0.090605 Validation Accuracy: 0.629400\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:   0.084402 Validation Accuracy: 0.630400\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:   0.089226 Validation Accuracy: 0.634000\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:   0.078803 Validation Accuracy: 0.632800\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:   0.066596 Validation Accuracy: 0.640400\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:   0.070474 Validation Accuracy: 0.640400\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:   0.065167 Validation Accuracy: 0.640600\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:   0.070267 Validation Accuracy: 0.636800\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:   0.069666 Validation Accuracy: 0.635400\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:   0.056589 Validation Accuracy: 0.635800\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:   0.061370 Validation Accuracy: 0.630600\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:   0.060373 Validation Accuracy: 0.632200\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:   0.061098 Validation Accuracy: 0.637000\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:   0.060470 Validation Accuracy: 0.638000\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:   0.052411 Validation Accuracy: 0.630400\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:   0.059348 Validation Accuracy: 0.630000\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:   0.066628 Validation Accuracy: 0.622000\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:   0.050897 Validation Accuracy: 0.636400\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:   0.051020 Validation Accuracy: 0.635400\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:   0.047446 Validation Accuracy: 0.629800\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:   0.048310 Validation Accuracy: 0.629600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:   0.045813 Validation Accuracy: 0.636600\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:   0.050318 Validation Accuracy: 0.625200\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:   0.056738 Validation Accuracy: 0.629400\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:   0.049726 Validation Accuracy: 0.621200\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:   0.050328 Validation Accuracy: 0.628200\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:   0.046198 Validation Accuracy: 0.626600\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:   0.055238 Validation Accuracy: 0.615800\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:   0.075044 Validation Accuracy: 0.611200\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:   0.050664 Validation Accuracy: 0.625600\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:   0.058203 Validation Accuracy: 0.619000\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:   0.047491 Validation Accuracy: 0.631000\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:   0.045053 Validation Accuracy: 0.622800\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:   0.042025 Validation Accuracy: 0.630200\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:   0.043543 Validation Accuracy: 0.632600\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:   0.060753 Validation Accuracy: 0.612800\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:   0.072812 Validation Accuracy: 0.600200\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:   0.051856 Validation Accuracy: 0.605800\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:   0.053126 Validation Accuracy: 0.620400\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:   0.040336 Validation Accuracy: 0.632400\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:   0.049035 Validation Accuracy: 0.625400\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:   0.041356 Validation Accuracy: 0.620800\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:   0.065498 Validation Accuracy: 0.596800\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:   0.046201 Validation Accuracy: 0.618000\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:   0.065429 Validation Accuracy: 0.610000\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:   0.067087 Validation Accuracy: 0.613000\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:   0.050760 Validation Accuracy: 0.607200\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:   0.048059 Validation Accuracy: 0.620000\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:   0.053347 Validation Accuracy: 0.607800\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:   0.038890 Validation Accuracy: 0.613400\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:   0.041692 Validation Accuracy: 0.619600\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:   0.048277 Validation Accuracy: 0.618200\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:   0.035242 Validation Accuracy: 0.618400\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:   0.051277 Validation Accuracy: 0.606600\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:   0.039602 Validation Accuracy: 0.604800\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:   0.043964 Validation Accuracy: 0.617200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:   0.040741 Validation Accuracy: 0.606000\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:   0.052963 Validation Accuracy: 0.616200\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:   0.035207 Validation Accuracy: 0.622200\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:   0.032798 Validation Accuracy: 0.602400\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:   0.033208 Validation Accuracy: 0.617000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:   0.043944 Validation Accuracy: 0.595600\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:   0.053260 Validation Accuracy: 0.601000\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:   0.027863 Validation Accuracy: 0.623400\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:   0.019054 Validation Accuracy: 0.626800\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:   0.019242 Validation Accuracy: 0.626600\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:   0.020976 Validation Accuracy: 0.618400\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:   0.022311 Validation Accuracy: 0.621400\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:   0.021248 Validation Accuracy: 0.617400\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:   0.016077 Validation Accuracy: 0.628000\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:   0.021800 Validation Accuracy: 0.624200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:   0.017451 Validation Accuracy: 0.629000\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:   0.020909 Validation Accuracy: 0.631600\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:   0.019045 Validation Accuracy: 0.623200\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:   0.017854 Validation Accuracy: 0.616400\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:   0.018434 Validation Accuracy: 0.621400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:   0.017738 Validation Accuracy: 0.621600\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:   0.017643 Validation Accuracy: 0.631800\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:   0.014000 Validation Accuracy: 0.633600\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:   0.013356 Validation Accuracy: 0.622600\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:   0.013245 Validation Accuracy: 0.632800\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:   0.019900 Validation Accuracy: 0.604000\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:   0.021800 Validation Accuracy: 0.625400\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:   0.019357 Validation Accuracy: 0.621600\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:   0.014313 Validation Accuracy: 0.631600\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:   0.011827 Validation Accuracy: 0.634000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:   0.010699 Validation Accuracy: 0.619400\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:   0.013746 Validation Accuracy: 0.631000\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:   0.010572 Validation Accuracy: 0.632000\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:   0.008103 Validation Accuracy: 0.630400\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:   0.007692 Validation Accuracy: 0.638600\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:   0.010108 Validation Accuracy: 0.623600\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:   0.010068 Validation Accuracy: 0.633000\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:   0.009074 Validation Accuracy: 0.626200\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:   0.007397 Validation Accuracy: 0.628400\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:   0.007975 Validation Accuracy: 0.636400\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:   0.007017 Validation Accuracy: 0.632400\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:   0.007641 Validation Accuracy: 0.633600\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:   0.008576 Validation Accuracy: 0.626800\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:   0.006065 Validation Accuracy: 0.623800\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:   0.006614 Validation Accuracy: 0.636000\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:   0.007075 Validation Accuracy: 0.634200\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:   0.008353 Validation Accuracy: 0.629200\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:   0.007056 Validation Accuracy: 0.628600\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:   0.005511 Validation Accuracy: 0.625400\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:   0.005917 Validation Accuracy: 0.636400\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:   0.007840 Validation Accuracy: 0.626000\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:   0.006332 Validation Accuracy: 0.626800\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:   0.005116 Validation Accuracy: 0.630600\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:   0.004591 Validation Accuracy: 0.627400\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:   0.005691 Validation Accuracy: 0.632200\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:   0.005319 Validation Accuracy: 0.627400\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:   0.005431 Validation Accuracy: 0.629400\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:   0.004417 Validation Accuracy: 0.635400\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:   0.005323 Validation Accuracy: 0.625200\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:   0.004620 Validation Accuracy: 0.628200\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:   0.004893 Validation Accuracy: 0.625800\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:   0.004959 Validation Accuracy: 0.634200\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:   0.004202 Validation Accuracy: 0.639400\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:   0.004729 Validation Accuracy: 0.620400\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:   0.005630 Validation Accuracy: 0.630200\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:   0.005281 Validation Accuracy: 0.628800\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:   0.004511 Validation Accuracy: 0.628400\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:   0.004910 Validation Accuracy: 0.635400\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:   0.004488 Validation Accuracy: 0.623200\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:   0.004504 Validation Accuracy: 0.632000\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:   0.004427 Validation Accuracy: 0.624800\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:   0.005101 Validation Accuracy: 0.634600\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:   0.005375 Validation Accuracy: 0.633400\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:   0.004045 Validation Accuracy: 0.627800\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:   0.003291 Validation Accuracy: 0.635600\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:   0.004127 Validation Accuracy: 0.633600\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:   0.003933 Validation Accuracy: 0.634400\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:   0.004090 Validation Accuracy: 0.641000\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:   0.003315 Validation Accuracy: 0.624400\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:   0.004002 Validation Accuracy: 0.631600\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:   0.004611 Validation Accuracy: 0.628200\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:   0.004125 Validation Accuracy: 0.630000\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:   0.004063 Validation Accuracy: 0.637800\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:   0.003822 Validation Accuracy: 0.625400\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:   0.004169 Validation Accuracy: 0.627000\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:   0.003951 Validation Accuracy: 0.632000\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:   0.003693 Validation Accuracy: 0.634000\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:   0.003336 Validation Accuracy: 0.636400\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:   0.003317 Validation Accuracy: 0.625200\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:   0.003771 Validation Accuracy: 0.623400\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:   0.004363 Validation Accuracy: 0.624200\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:   0.003345 Validation Accuracy: 0.632200\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:   0.003719 Validation Accuracy: 0.628800\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:   0.004273 Validation Accuracy: 0.622600\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:   0.003773 Validation Accuracy: 0.624600\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:   0.004673 Validation Accuracy: 0.622400\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:   0.003672 Validation Accuracy: 0.629200\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:   0.003525 Validation Accuracy: 0.628200\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:   0.002474 Validation Accuracy: 0.626800\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:   0.003455 Validation Accuracy: 0.629600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:   0.005022 Validation Accuracy: 0.624400\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:   0.004220 Validation Accuracy: 0.621400\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:   0.004162 Validation Accuracy: 0.619800\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:   0.002271 Validation Accuracy: 0.632600\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:   0.003220 Validation Accuracy: 0.630800\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:   0.004140 Validation Accuracy: 0.626800\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:   0.004875 Validation Accuracy: 0.616400\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:   0.006010 Validation Accuracy: 0.617800\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:   0.003304 Validation Accuracy: 0.627200\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:   0.004313 Validation Accuracy: 0.617800\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:   0.004294 Validation Accuracy: 0.627800\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:   0.004410 Validation Accuracy: 0.618800\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:   0.003161 Validation Accuracy: 0.631200\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:   0.002386 Validation Accuracy: 0.635400\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:   0.002972 Validation Accuracy: 0.633200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:   0.001993 Validation Accuracy: 0.632000\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:   0.002152 Validation Accuracy: 0.629600\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:   0.002545 Validation Accuracy: 0.621600\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:   0.002090 Validation Accuracy: 0.622200\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:   0.002514 Validation Accuracy: 0.628200\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:   0.002617 Validation Accuracy: 0.627000\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:   0.002250 Validation Accuracy: 0.629000\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:   0.001973 Validation Accuracy: 0.628800\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:   0.001371 Validation Accuracy: 0.633800\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:   0.002040 Validation Accuracy: 0.627400\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:   0.001640 Validation Accuracy: 0.630800\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:   0.001790 Validation Accuracy: 0.631200\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:   0.001586 Validation Accuracy: 0.630200\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:   0.001793 Validation Accuracy: 0.635400\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:   0.001833 Validation Accuracy: 0.626600\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:   0.001490 Validation Accuracy: 0.622400\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:   0.001681 Validation Accuracy: 0.625600\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:   0.002302 Validation Accuracy: 0.624800\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:   0.001235 Validation Accuracy: 0.625800\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:   0.001266 Validation Accuracy: 0.629400\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:   0.001001 Validation Accuracy: 0.625200\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:   0.001929 Validation Accuracy: 0.629800\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:   0.001679 Validation Accuracy: 0.629600\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:   0.002308 Validation Accuracy: 0.615200\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:   0.001864 Validation Accuracy: 0.621000\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:   0.001954 Validation Accuracy: 0.613400\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:   0.003088 Validation Accuracy: 0.626000\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:   0.001865 Validation Accuracy: 0.627000\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:   0.001716 Validation Accuracy: 0.626400\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:   0.001844 Validation Accuracy: 0.624000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:   0.001873 Validation Accuracy: 0.623600\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:   0.002260 Validation Accuracy: 0.628400\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:   0.001493 Validation Accuracy: 0.632400\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:   0.001332 Validation Accuracy: 0.623600\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:   0.001560 Validation Accuracy: 0.627400\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:   0.001432 Validation Accuracy: 0.623400\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:   0.002394 Validation Accuracy: 0.630800\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:   0.001452 Validation Accuracy: 0.634000\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:   0.001535 Validation Accuracy: 0.626600\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:   0.001163 Validation Accuracy: 0.626000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:   0.001960 Validation Accuracy: 0.611800\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:   0.002524 Validation Accuracy: 0.624200\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:   0.002617 Validation Accuracy: 0.621400\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:   0.001393 Validation Accuracy: 0.625200\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:   0.001850 Validation Accuracy: 0.624200\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:   0.001114 Validation Accuracy: 0.623000\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:   0.001924 Validation Accuracy: 0.620000\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:   0.001339 Validation Accuracy: 0.629800\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:   0.001095 Validation Accuracy: 0.632800\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:   0.001104 Validation Accuracy: 0.630800\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:   0.001661 Validation Accuracy: 0.620000\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:   0.002192 Validation Accuracy: 0.618600\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:   0.001672 Validation Accuracy: 0.625800\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:   0.001240 Validation Accuracy: 0.625400\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:   0.001293 Validation Accuracy: 0.627000\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:   0.001573 Validation Accuracy: 0.614800\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:   0.003054 Validation Accuracy: 0.613600\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:   0.002823 Validation Accuracy: 0.618200\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:   0.001824 Validation Accuracy: 0.623000\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:   0.001252 Validation Accuracy: 0.623600\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:   0.000813 Validation Accuracy: 0.630800\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:   0.001447 Validation Accuracy: 0.629800\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:   0.001383 Validation Accuracy: 0.624600\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:   0.002115 Validation Accuracy: 0.608400\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:   0.001694 Validation Accuracy: 0.622000\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:   0.001289 Validation Accuracy: 0.620800\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:   0.001625 Validation Accuracy: 0.628800\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:   0.001880 Validation Accuracy: 0.620000\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:   0.001659 Validation Accuracy: 0.616200\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:   0.001930 Validation Accuracy: 0.623200\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:   0.001771 Validation Accuracy: 0.620600\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:   0.002285 Validation Accuracy: 0.617200\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:   0.001017 Validation Accuracy: 0.631800\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:   0.000904 Validation Accuracy: 0.621800\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:   0.000952 Validation Accuracy: 0.628200\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:   0.000788 Validation Accuracy: 0.628200\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:   0.001308 Validation Accuracy: 0.628000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:   0.000659 Validation Accuracy: 0.631000\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:   0.000931 Validation Accuracy: 0.616800\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:   0.001108 Validation Accuracy: 0.625600\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:   0.001328 Validation Accuracy: 0.626200\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:   0.001138 Validation Accuracy: 0.632600\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:   0.000622 Validation Accuracy: 0.633000\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:   0.000772 Validation Accuracy: 0.629600\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:   0.000771 Validation Accuracy: 0.627000\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:   0.000739 Validation Accuracy: 0.626200\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:   0.001522 Validation Accuracy: 0.629800\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:   0.000732 Validation Accuracy: 0.633400\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:   0.001251 Validation Accuracy: 0.612400\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:   0.000744 Validation Accuracy: 0.626800\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:   0.000523 Validation Accuracy: 0.629800\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:   0.002386 Validation Accuracy: 0.626000\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:   0.001066 Validation Accuracy: 0.620400\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:   0.000834 Validation Accuracy: 0.612400\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:   0.000818 Validation Accuracy: 0.629800\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:   0.000587 Validation Accuracy: 0.630000\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:   0.001121 Validation Accuracy: 0.621400\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:   0.000726 Validation Accuracy: 0.622000\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:   0.000709 Validation Accuracy: 0.620600\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:   0.000688 Validation Accuracy: 0.631400\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:   0.000669 Validation Accuracy: 0.625200\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:   0.002181 Validation Accuracy: 0.609200\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:   0.000883 Validation Accuracy: 0.622200\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:   0.001004 Validation Accuracy: 0.613800\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:   0.000954 Validation Accuracy: 0.621800\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:   0.001168 Validation Accuracy: 0.621600\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:   0.002219 Validation Accuracy: 0.610600\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:   0.000838 Validation Accuracy: 0.623200\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:   0.000685 Validation Accuracy: 0.627000\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:   0.002100 Validation Accuracy: 0.610200\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:   0.000883 Validation Accuracy: 0.624000\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:   0.001252 Validation Accuracy: 0.619600\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:   0.000822 Validation Accuracy: 0.628200\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:   0.000866 Validation Accuracy: 0.629200\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:   0.000848 Validation Accuracy: 0.618800\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:   0.000449 Validation Accuracy: 0.626600\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:   0.000730 Validation Accuracy: 0.628400\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:   0.000602 Validation Accuracy: 0.628200\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:   0.000468 Validation Accuracy: 0.629600\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:   0.000725 Validation Accuracy: 0.623000\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:   0.000445 Validation Accuracy: 0.628000\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:   0.000780 Validation Accuracy: 0.623200\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:   0.000446 Validation Accuracy: 0.635000\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:   0.000399 Validation Accuracy: 0.634000\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:   0.000585 Validation Accuracy: 0.629600\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:   0.000302 Validation Accuracy: 0.632800\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:   0.000915 Validation Accuracy: 0.624600\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:   0.000317 Validation Accuracy: 0.634000\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:   0.000273 Validation Accuracy: 0.636800\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:   0.001013 Validation Accuracy: 0.625600\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:   0.000270 Validation Accuracy: 0.630000\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:   0.000780 Validation Accuracy: 0.626200\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:   0.000381 Validation Accuracy: 0.632000\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:   0.000384 Validation Accuracy: 0.627800\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:   0.000390 Validation Accuracy: 0.629600\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:   0.000488 Validation Accuracy: 0.635400\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:   0.000522 Validation Accuracy: 0.629600\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:   0.000307 Validation Accuracy: 0.628600\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:   0.000258 Validation Accuracy: 0.634200\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:   0.000677 Validation Accuracy: 0.623000\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:   0.000195 Validation Accuracy: 0.631800\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:   0.000518 Validation Accuracy: 0.624200\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:   0.000602 Validation Accuracy: 0.625800\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:   0.000488 Validation Accuracy: 0.622000\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:   0.000888 Validation Accuracy: 0.616200\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:   0.000444 Validation Accuracy: 0.629600\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:   0.001568 Validation Accuracy: 0.627000\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:   0.000344 Validation Accuracy: 0.630000\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:   0.000379 Validation Accuracy: 0.626200\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:   0.000795 Validation Accuracy: 0.620600\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:   0.000480 Validation Accuracy: 0.626000\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:   0.000732 Validation Accuracy: 0.631600\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:   0.000349 Validation Accuracy: 0.629000\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:   0.000262 Validation Accuracy: 0.634600\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:   0.000363 Validation Accuracy: 0.632600\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:   0.000397 Validation Accuracy: 0.637600\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:   0.000386 Validation Accuracy: 0.630600\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:   0.000375 Validation Accuracy: 0.628400\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:   0.000308 Validation Accuracy: 0.623800\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:   0.000355 Validation Accuracy: 0.625000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.6209900498390197\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb22c6abf60>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
